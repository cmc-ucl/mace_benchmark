{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking mace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pymatgen.core.structure import Structure\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from ase.io import read\n",
    "from ase.data import chemical_symbols\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.constants import physical_constants\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import shutil as sh\n",
    "\n",
    "from janus_core.calculations.single_point import SinglePoint\n",
    "from janus_core.calculations.geom_opt import GeomOpt\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "from structure_generation import get_all_configurations_pmg, write_extended_xyz, generate_random_structures, \\\n",
    "    write_CRYSTAL_gui_from_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlGaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brunocamino/miniconda3/envs/mace-test/lib/python3.11/site-packages/pymatgen/io/cif.py:1290: UserWarning: Issues encountered while parsing CIF: 8 fractional coordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  warnings.warn(\"Issues encountered while parsing CIF: \" + \"\\n\".join(self.warnings))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlN_bulk = Structure.from_file('data/bulk_structures/AlN.cif')\n",
    "\n",
    "supercell_matrix = np.eye(3)*3\n",
    "\n",
    "AlN_super3 = copy.deepcopy(AlN_bulk)\n",
    "\n",
    "AlN_super3.make_supercell(supercell_matrix)\n",
    "\n",
    "AlN_super3.num_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaN_bulk = Structure.from_file('data/bulk_structures/GaN.cif')\n",
    "\n",
    "supercell_matrix = np.eye(3)*3\n",
    "\n",
    "GaN_super3 = copy.deepcopy(GaN_bulk)\n",
    "\n",
    "GaN_super3.make_supercell(supercell_matrix)\n",
    "\n",
    "GaN_super3.num_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atom_indices_aln = get_all_configurations_pmg(AlN_super3)\n",
    "# np.savetxt('data/symmetry/aln_108_atom_indices.csv',atom_indices_aln,delimiter=',',fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_indices_aln = np.genfromtxt('data/symmetry/aln_108_atom_indices.csv',delimiter=',').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_sites=np.where(np.array(AlN_super3.atomic_numbers) == 13)[0]\n",
    "num_active_sites=len(active_sites)\n",
    "\n",
    "N_atom = 31\n",
    "\n",
    "all_config_atom_number = {}\n",
    "\n",
    "for n,N_atoms in enumerate(np.arange(1,54)):\n",
    "\n",
    "    structures_random = generate_random_structures(AlN_super3,atom_indices=atom_indices_aln,\n",
    "                                                   N_atoms=N_atoms,new_species=31,N_config=500,\n",
    "                                                   DFT_config=20,active_sites=active_sites)\n",
    "\n",
    "    atom_number_tmp = []\n",
    "    for structure in structures_random:\n",
    "        atom_number_tmp.append(list(structure.atomic_numbers))\n",
    "\n",
    "    all_config_atom_number[str(N_atoms)] = atom_number_tmp\n",
    "\n",
    "# with open('data/supercell_structures/AlGaN/AlGaN_super3.json', 'w') as json_file:\n",
    "#     json.dump(all_config_atom_number, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/supercell_structures/AlGaN/AlGaN_super3.json', 'r', encoding='utf-8') as json_file:\n",
    "    AlGaN_super3_all_config = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Extended XYZ files\n",
    "\n",
    "lattice = AlN_super3.lattice.matrix\n",
    "positions = AlN_super3.frac_coords\n",
    "for N_atoms in AlGaN_super3_all_config.keys():\n",
    "    \n",
    "    folder_name = f'data/supercell_structures/AlGaN/AlGaN_super3_{N_atoms}'\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    \n",
    "    for i,config in enumerate(AlGaN_super3_all_config[N_atoms]):\n",
    "        structure = Structure(lattice,config,positions)\n",
    "\n",
    "        write_extended_xyz(structure,os.path.join(folder_name,f'AlGaN_super3_{N_atoms}_{i}.xyz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write CRYSTAL input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_slurm_file(file_names_list, project_code='e05-algor-smw'):\n",
    "\n",
    "    bash_script = [\n",
    "    '#!/bin/bash\\n',\n",
    "    f'#SBATCH --nodes={len(file_names_list)}\\n',\n",
    "    '#SBATCH --ntasks-per-node=128\\n',\n",
    "    '#SBATCH --cpus-per-task=1\\n',\n",
    "    '#SBATCH --time=24:00:00\\n\\n',\n",
    "    '# Replace [budget code] below with your full project code\\n',\n",
    "    f'#SBATCH --account={project_code}\\n',\n",
    "    '#SBATCH --partition=standard\\n',\n",
    "    '#SBATCH --qos=standard\\n',\n",
    "    '#SBATCH --export=none\\n\\n',\n",
    "    'module load epcc-job-env\\n',\n",
    "    'module load other-software\\n',\n",
    "    'module load crystal\\n\\n',\n",
    "    '# Address the memory leak\\n',\n",
    "    'export FI_MR_CACHE_MAX_COUNT=0\\n',\n",
    "    'export SLURM_CPU_FREQ_REQ=2250000\\n\\n',\n",
    "    '# Run calculations\\n'\n",
    "]\n",
    "\n",
    "    for file in file_names_list:\n",
    "        bash_script.append(f'timeout 1430m /work/e05/e05/bcamino/runCRYSTAL/Pcry_slurm_multi {file[:-4]} &\\n')\n",
    "\n",
    "    bash_script.append('wait')\n",
    "\n",
    "    return bash_script\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlN_lattice_matrix = np.round(AlN_super3.lattice.matrix[0:3], 6)\n",
    "GaN_lattice_matrix = np.round(GaN_super3.lattice.matrix[0:3], 6)\n",
    "\n",
    "AlGaN_lattice_matrix = (AlN_lattice_matrix + GaN_lattice_matrix)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from structure_generation import write_CRYSTAL_gui_from_data\n",
    "\n",
    "\n",
    "lattice_matrix = AlGaN_lattice_matrix\n",
    "cart_coords = np.round(AlN_super3.cart_coords,8)\n",
    "\n",
    "\n",
    "for N_atoms in AlGaN_super3_all_config.keys():\n",
    "    \n",
    "    for i,config in enumerate(AlGaN_super3_all_config[N_atoms]):\n",
    "\n",
    "        atomic_numbers = config\n",
    "\n",
    "        folder_name = f'data/crystal/AlGaN/super3/config_{i}/'\n",
    "        file_name = f'AlGaN_super3_{N_atoms}_{i}_0.gui'\n",
    "        full_name = os.path.join(folder_name,file_name)\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "        \n",
    "        for i,config in enumerate(AlGaN_super3_all_config[N_atoms]):\n",
    "            structure = Structure(lattice_matrix,config,cart_coords)\n",
    "\n",
    "            write_CRYSTAL_gui_from_data(lattice_matrix,atomic_numbers,\n",
    "                                cart_coords, full_name, dimensionality = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'data/crystal/AlGaN/super3/'\n",
    "\n",
    "folders = [name for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))]\n",
    "\n",
    "for folder in folders:\n",
    "\n",
    "    folder_path_new = os.path.join(folder_path,folder)\n",
    "    slurm_file_name = os.path.join(folder_path_new,f'{folder}_0.slurm')\n",
    "    files = [name for name in os.listdir(folder_path_new) \n",
    "         if os.path.isfile(os.path.join(folder_path_new, name)) and name.endswith('.gui')]\n",
    "\n",
    "    # copy .d12\n",
    "    for file in files:\n",
    "        input_file = os.path.join(folder_path_new,f'{file[:-4]}.d12')\n",
    "        sh.copy('data/crystal/AlGaN/super3/super3_input.d12', input_file)\n",
    "\n",
    "    bash_script = generate_slurm_file(files)\n",
    "    with open(slurm_file_name, 'w') as file:\n",
    "        for line in bash_script:\n",
    "            file.write(f\"{line}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CRYSTAL output files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the units (stress is in Bohr^3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/crystal/AlGaN/super3/output_files/AlGaN_super3_1_0_0.out', 'r') as f:\n",
    "    file_content = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lattice_params_to_matrix(a, b, c, alpha, beta, gamma):\n",
    "    \"\"\"\n",
    "    Convert lattice parameters to a 3x3 lattice matrix.\n",
    "\n",
    "    Parameters:\n",
    "        a, b, c (float): Lattice constants.\n",
    "        alpha, beta, gamma (float): Angles (in degrees) between the lattice vectors.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 3x3 lattice matrix.\n",
    "    \"\"\"\n",
    "    # Convert angles from degrees to radians\n",
    "    alpha_rad = np.radians(alpha)\n",
    "    beta_rad = np.radians(beta)\n",
    "    gamma_rad = np.radians(gamma)\n",
    "\n",
    "    # Compute the lattice vectors\n",
    "    v_x = a\n",
    "    v_y = b * np.cos(gamma_rad)\n",
    "    v_z = c * np.cos(beta_rad)\n",
    "\n",
    "    w_y = b * np.sin(gamma_rad)\n",
    "    w_z = c * (np.cos(alpha_rad) - np.cos(beta_rad) * np.cos(gamma_rad)) / np.sin(gamma_rad)\n",
    "\n",
    "    u_z = np.sqrt(c**2 - v_z**2 - w_z**2)\n",
    "\n",
    "    # Assemble the lattice matrix\n",
    "    lattice_matrix = np.array([\n",
    "        [v_x, 0, 0],\n",
    "        [v_y, w_y, 0],\n",
    "        [v_z, w_z, u_z],\n",
    "    ])\n",
    "\n",
    "    return lattice_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion factors\n",
    "HARTREE_TO_EV = physical_constants['Hartree energy in eV'][0]\n",
    "BOHR_TO_ANGSTROM = physical_constants['Bohr radius'][0] * 1e10  # Convert meters to Ångstrom\n",
    "BOHR_CUBED_TO_ANGSTROM_CUBED = BOHR_TO_ANGSTROM**3\n",
    "\n",
    "def parse_extended_xyz(file_content, num_atoms):\n",
    "    \"\"\"\n",
    "    Parse the file to extract structures and convert lattice parameters, coordinates, energy, forces,\n",
    "    and stress tensor to standard units (e.g., eV, Å).\n",
    "    \"\"\"\n",
    "    def extract_floats(line):\n",
    "        \"\"\"Helper function to extract floats from a string.\"\"\"\n",
    "        return list(map(float, re.findall(r\"[-+]?\\d*\\.\\d+(?:[Ee][-+]?\\d+)?\", line)))\n",
    "\n",
    "    results = []\n",
    "    structure_data = {}\n",
    "\n",
    "    for i, line in enumerate(file_content):\n",
    "        line = line.strip()\n",
    "\n",
    "        # Lattice parameters\n",
    "        if \"ATOM                 X/A                 Y/B                 Z/C\" in line:\n",
    "            lattice_params = extract_floats(file_content[i - 3])\n",
    "            if len(lattice_params) == 6:\n",
    "                a, b, c, alpha, beta, gamma = lattice_params\n",
    "                structure_data['lattice_matrix'] = lattice_params_to_matrix(a, b, c, alpha, beta, gamma)\n",
    "\n",
    "        # Fractional coordinates and atomic symbols\n",
    "        if \"ATOM                 X/A                 Y/B                 Z/C\" in line:\n",
    "            start = i + 2\n",
    "            fractional_coords = []\n",
    "            atomic_symbols = []\n",
    "            for j in range(num_atoms):\n",
    "                coord_line = file_content[start + j].strip()\n",
    "                parts = coord_line.split()\n",
    "                atomic_number = int(parts[2])  # Third element is the atomic number\n",
    "                atomic_symbols.append(chemical_symbols[atomic_number])  # Convert to symbol\n",
    "                fractional_coords.append(extract_floats(coord_line))\n",
    "\n",
    "            structure_data['fractional_coordinates'] = fractional_coords\n",
    "            structure_data['atomic_symbols'] = atomic_symbols\n",
    "\n",
    "            # Calculate Cartesian coordinates\n",
    "            lattice_matrix = structure_data['lattice_matrix']\n",
    "            structure_data['cartesian_coordinates'] = [\n",
    "                np.dot(coord, lattice_matrix) for coord in fractional_coords\n",
    "            ]\n",
    "\n",
    "        # Energy\n",
    "        if \"== SCF ENDED - CONVERGENCE ON ENERGY      E(AU)\" in line:\n",
    "            energy_hartree = extract_floats(line)[0]\n",
    "            structure_data['energy_ev'] = energy_hartree * HARTREE_TO_EV\n",
    "\n",
    "        # Forces\n",
    "        if \"CARTESIAN FORCES IN HARTREE/BOHR (ANALYTICAL)\" in line:\n",
    "            start = i + 2\n",
    "            structure_data['forces'] = [\n",
    "                extract_floats(file_content[start + j])\n",
    "                for j in range(num_atoms)\n",
    "            ]\n",
    "\n",
    "        # Stress tensor\n",
    "        if \"STRESS TENSOR, IN HARTREE/BOHR^3:\" in line:\n",
    "            start = i + 4\n",
    "            stress_hartree_bohr3 = [\n",
    "                extract_floats(file_content[start + j]) for j in range(3)\n",
    "            ]\n",
    "            stress_ev_angstrom3 = np.array(stress_hartree_bohr3) * (HARTREE_TO_EV / BOHR_CUBED_TO_ANGSTROM_CUBED)\n",
    "            structure_data['stress'] = stress_ev_angstrom3.tolist()\n",
    "\n",
    "        # Store the structure if all required fields are found\n",
    "        if all(key in structure_data for key in ['lattice_matrix', 'fractional_coordinates', 'cartesian_coordinates', 'energy_ev', 'forces', 'stress', 'atomic_symbols']):\n",
    "            results.append(structure_data.copy())\n",
    "            structure_data = {}  # Reset for the next structure\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_extended_xyz_files_from_df(df, seed_name, start_index):\n",
    "    \"\"\"\n",
    "    Generate extended XYZ files from a DataFrame containing structure data in ASE extended format.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing columns:\n",
    "            - 'cartesian_coordinates': List of Cartesian coordinates.\n",
    "            - 'atomic_symbols': List of atomic symbols.\n",
    "            - 'energy_ev': Energy in eV.\n",
    "            - 'forces': List of forces for each atom.\n",
    "            - 'stress': Stress tensor for the structure.\n",
    "            - 'lattice_matrix': Lattice matrix.\n",
    "        seed_name (str): Base name for output files.\n",
    "        start_index (int): Starting index for numbering the output files.\n",
    "\n",
    "    Returns:\n",
    "        int: Updated index after processing all structures.\n",
    "    \"\"\"\n",
    "    index = start_index\n",
    "    for _, row in df.iterrows():\n",
    "        # Filename with incrementing index\n",
    "        filename = f\"{seed_name}_{index}.xyz\"\n",
    "\n",
    "        # Extract data\n",
    "        cartesian_coords = row['cartesian_coordinates']\n",
    "        atomic_symbols = row['atomic_symbols']\n",
    "        energy = row['energy_ev']\n",
    "        forces = row['forces']\n",
    "        stress = row['stress']\n",
    "        lattice_matrix = row['lattice_matrix']\n",
    "        num_atoms = len(cartesian_coords)\n",
    "\n",
    "        # Generate content\n",
    "        content = []\n",
    "        # First line: Number of atoms\n",
    "        content.append(str(num_atoms))\n",
    "        # Second line: Metadata (energy, lattice matrix, stress tensor, properties, config type)\n",
    "        lattice_flat = \" \".join(f\"{value:.12e}\" for row in lattice_matrix for value in row)\n",
    "        stress_flat = \" \".join(f\"{value:.12e}\" for row in stress for value in row)\n",
    "        content.append(\n",
    "            f'Energy={energy:.12e} '\n",
    "            f'Lattice=\"{lattice_flat}\" '\n",
    "            f'Stress=\"{stress_flat}\" '\n",
    "            f'Properties=species:S:1:pos:R:3:forces:R:3 '\n",
    "            f'Config_type={filename}'\n",
    "        )\n",
    "        # Atom lines with forces\n",
    "        for atomic_symbol, atom, force in zip(atomic_symbols, cartesian_coords, forces):\n",
    "            content.append(\n",
    "                f\"{atomic_symbol} {atom[0]:.12e} {atom[1]:.12e} {atom[2]:.12e} \"\n",
    "                f\"{force[0]:.12e} {force[1]:.12e} {force[2]:.12e}\"\n",
    "            )\n",
    "\n",
    "        # Write to file\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(\"\\n\".join(content) + \"\\n\")\n",
    "\n",
    "        # Increment index\n",
    "        index += 1\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written: data/crystal/AlGaN/super3/output_files/test_1.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_2.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_3.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_4.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_5.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_6.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_7.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_8.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_9.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_10.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_11.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_12.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_13.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_14.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_15.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_16.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_17.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_18.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_19.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_20.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_21.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_22.xyz\n",
      "File written: data/crystal/AlGaN/super3/output_files/test_23.xyz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# num_atoms = 108  \n",
    "# # Parse the file and extract structures with lattice matrix conversion\n",
    "# parsed_structures = parse_extended_xyz(file_content, num_atoms)\n",
    "\n",
    "# # Convert to DataFrame for inspection\n",
    "# df_structures = pd.DataFrame(parsed_structures)\n",
    "\n",
    "# # Generate extended XYZ files\n",
    "# generate_extended_xyz_files_from_df(df_structures, 'data/crystal/AlGaN/super3/output_files/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write all the extxyz from all output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all the extxyz from all output files\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Folder containing the .out files\n",
    "folder_path = \"data/crystal/AlGaN/super3/output_files\"\n",
    "output_folder = \"data/crystal/AlGaN/super3/extxyz_files\"\n",
    "os.makedirs(output_folder, exist_ok=True)  # Ensure the output folder exists\n",
    "\n",
    "# Loop over X values\n",
    "for X in np.arange(54):  # Adjust the range as needed\n",
    "    for Y in np.arange(10):  # Adjust the range as needed\n",
    "        # Global index for structures extracted for the current X and Y\n",
    "        global_index = 0\n",
    "        Z = 0\n",
    "\n",
    "        while True:\n",
    "            # Construct file path for the current Z\n",
    "            file_name = f\"AlGaN_super3_{X}_{Y}_{Z}.out\"\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            # Check if the file exists\n",
    "            if not os.path.exists(file_path):\n",
    "                break  # Exit the loop when no more Z files exist for this X_Y\n",
    "\n",
    "            # Read the file and process its content\n",
    "            with open(file_path, \"r\") as f:\n",
    "                file_content = f.readlines()\n",
    "\n",
    "            # Parse the file content\n",
    "            parsed_structures = parse_extended_xyz(file_content, num_atoms=108)  # Replace 108 with your atom count\n",
    "\n",
    "            # Convert parsed structures to a DataFrame\n",
    "            df_structures = pd.DataFrame(parsed_structures)\n",
    "\n",
    "            # Save all extracted structures with unique global indices\n",
    "            for _, row in df_structures.iterrows():\n",
    "                # Generate the output file name with the incrementing global index\n",
    "                output_file = os.path.join(\n",
    "                    output_folder, f\"AlGaN_super3_{X}_{Y}_{global_index}.xyz\"\n",
    "                )\n",
    "\n",
    "                # Write the structure to an extended XYZ file\n",
    "                with open(output_file, \"w\") as out_f:\n",
    "                    # Write number of atoms\n",
    "                    num_atoms = len(row['cartesian_coordinates'])\n",
    "                    out_f.write(f\"{num_atoms}\\n\")\n",
    "\n",
    "                    # Write metadata\n",
    "                    lattice_flat = \" \".join(f\"{value:.12e}\" for value in row['lattice_matrix'].flatten())\n",
    "                    stress_flat = \" \".join(f\"{value:.12e}\" for value in np.array(row['stress']).flatten())\n",
    "                    out_f.write(\n",
    "                        f\"dft_energy={row['energy_ev']:.12e} \"\n",
    "                        f'Lattice=\"{lattice_flat}\" '\n",
    "                        f'dft_stress=\"{stress_flat}\" '\n",
    "                        f'Properties=species:S:1:pos:R:3:dft_forces:R:3 '\n",
    "                        f'config_type=random '\n",
    "                        # f'system_name={os.path.basename(output_file[:-4])}\\n'\n",
    "                        f'system_name=random\\n'\n",
    "                    )\n",
    "\n",
    "                    # Write atomic data\n",
    "                    for symbol, coord, force in zip(row['atomic_symbols'], row['cartesian_coordinates'], row['forces']):\n",
    "                        out_f.write(\n",
    "                            f\"{symbol} {coord[0]:.12e} {coord[1]:.12e} {coord[2]:.12e} \"\n",
    "                            f\"{force[0]:.12e} {force[1]:.12e} {force[2]:.12e}\\n\"\n",
    "                        )\n",
    "\n",
    "                # Increment the global index\n",
    "                global_index += 1\n",
    "\n",
    "            # Increment Z to process the next file\n",
    "            Z += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for dusplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate files found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "\n",
    "def calculate_file_hash(file_path, hash_algo=\"md5\"):\n",
    "    \"\"\"\n",
    "    Calculate the hash of a file using the specified algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the file.\n",
    "        hash_algo (str): Hash algorithm to use (default: \"md5\").\n",
    "    \n",
    "    Returns:\n",
    "        str: Hexadecimal hash of the file content.\n",
    "    \"\"\"\n",
    "    hash_func = hashlib.new(hash_algo)\n",
    "    with open(file_path, 'rb') as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_func.update(chunk)\n",
    "    return hash_func.hexdigest()\n",
    "\n",
    "def find_duplicate_files(folder_path, pattern_prefix):\n",
    "    \"\"\"\n",
    "    Find duplicate files in a folder for a given pattern prefix.\n",
    "    \n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing files.\n",
    "        pattern_prefix (str): Prefix pattern for filtering files (e.g., \"AlGaN_super3_X_Y_\").\n",
    "    \n",
    "    Returns:\n",
    "        list of tuple: List of duplicate file pairs (file1, file2).\n",
    "    \"\"\"\n",
    "    # Filter files matching the pattern\n",
    "    files = [f for f in os.listdir(folder_path) if f.startswith(pattern_prefix)]\n",
    "    file_hashes = {}\n",
    "    duplicates = []\n",
    "\n",
    "    # Calculate hashes for each file\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        file_hash = calculate_file_hash(file_path)\n",
    "        if file_hash in file_hashes:\n",
    "            # Found a duplicate\n",
    "            duplicates.append((file_hashes[file_hash], file))\n",
    "        else:\n",
    "            file_hashes[file_hash] = file\n",
    "\n",
    "    return duplicates\n",
    "\n",
    "# Folder containing the .out files\n",
    "folder_path = \"data/crystal/AlGaN/super3/extxyz_files/\"\n",
    "\n",
    "# Example: Check for duplicates in AlGaN_super3_1_0_*\n",
    "x = 1\n",
    "y = 1\n",
    "pattern_prefix = f\"AlGaN_super3_{x}_{y}_\"\n",
    "duplicates = find_duplicate_files(folder_path, pattern_prefix)\n",
    "\n",
    "if duplicates:\n",
    "    print(\"Duplicate files found:\")\n",
    "    for file1, file2 in duplicates:\n",
    "        print(f\"{file1} and {file2}\")\n",
    "else:\n",
    "    print(\"No duplicate files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All .xyz files in 'data/crystal/AlGaN/super3/extxyz_files' have been concatenated into 'data/crystal/AlGaN/super3/concatenated_files/AlGaN_super3_all.xyz'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def concatenate_xyz_files(input_folder, output_file):\n",
    "    \"\"\"\n",
    "    Concatenate all .xyz files in a folder into a single .xyz file.\n",
    "\n",
    "    Parameters:\n",
    "        input_folder (str): Path to the folder containing .xyz files.\n",
    "        output_file (str): Path to the output .xyz file.\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for file_name in sorted(os.listdir(input_folder)):\n",
    "            if file_name.endswith(\".xyz\"):\n",
    "                file_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "                # Read the content of the current .xyz file\n",
    "                with open(file_path, 'r') as infile:\n",
    "                    content = infile.read()\n",
    "                \n",
    "                # Append content to the output file\n",
    "                outfile.write(content)\n",
    "\n",
    "    print(f\"All .xyz files in '{input_folder}' have been concatenated into '{output_file}'.\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = \"data/crystal/AlGaN/super3/extxyz_files\"\n",
    "output_file = \"data/crystal/AlGaN/super3/concatenated_files/AlGaN_super3_all.xyz\"\n",
    "concatenate_xyz_files(input_folder, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read structures ASE\n",
    "\n",
    "The stress is rounded, change to full value from CRYSTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = \"data/crystal/AlGaN/super3/concatenated_files/AlGaN_super3_all.xyz\"\n",
    "atoms = read(test_file, index=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Directory containing the extxyz files\n",
    "# directory = 'data/crystal/AlGaN/super3/extxyz_files/'\n",
    "\n",
    "# # List to store the atoms and stress tensors\n",
    "# atoms_list = []\n",
    "# stress_list = []\n",
    "\n",
    "# # Iterate over all files in the directory\n",
    "# for filename in os.listdir(directory):\n",
    "#     if filename.endswith('.xyz'):  # Only process .extxyz files\n",
    "#         file_path = os.path.join(directory, filename)\n",
    "        \n",
    "#         # Read the ASE atoms object\n",
    "#         atoms = read(file_path, format='extxyz')\n",
    "#         atoms_list.append(atoms)\n",
    "        \n",
    "#         # Extract the stress tensor if it exists\n",
    "#         stress_flat = atoms.info.get(\"Stress\")\n",
    "#         if stress_flat is not None:\n",
    "#             stress = stress_flat.reshape(3, 3)\n",
    "#             stress_list.append(stress)\n",
    "#         else:\n",
    "#             print(f\"No stress information found in {filename}\")\n",
    "#             stress_list.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test/Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total structures: 4353\n",
      "Training set: 3483 structures\n",
      "Testing set: 870 structures\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to numpy arrays for easier indexing\n",
    "atoms_array = np.array(atoms_list, dtype=object)\n",
    "stress_array = np.array(stress_list, dtype=object)\n",
    "\n",
    "# Generate random indices for train-test split\n",
    "n_samples = len(atoms_array)\n",
    "test_size = 0.2\n",
    "n_test = int(n_samples * test_size)\n",
    "\n",
    "# Create a random permutation of indices\n",
    "indices = np.arange(n_samples)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Split indices for train and test sets\n",
    "test_indices = indices[:n_test]\n",
    "train_indices = indices[n_test:]\n",
    "\n",
    "# Split the data\n",
    "atoms_train = atoms_array[train_indices]\n",
    "atoms_test = atoms_array[test_indices]\n",
    "stress_train = stress_array[train_indices]\n",
    "stress_test = stress_array[test_indices]\n",
    "\n",
    "# Output information\n",
    "print(f\"Total structures: {n_samples}\")\n",
    "print(f\"Training set: {len(atoms_train)} structures\")\n",
    "print(f\"Testing set: {len(atoms_test)} structures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mace geometry optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mace_geom_opt(atoms):\n",
    "\n",
    "    atoms_sp = SinglePoint(\n",
    "        struct=atoms.copy(),\n",
    "        arch=\"mace_mp\",\n",
    "        device='cpu',\n",
    "        calc_kwargs={'model_paths':'small','default_dtype':'float64'},\n",
    "    )\n",
    "\n",
    "    atoms_opt = GeomOpt(\n",
    "        struct=atoms_sp.struct,\n",
    "        fmax=0.001,\n",
    "    )\n",
    "\n",
    "    atoms_opt.run()\n",
    "\n",
    "    return atoms_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.561583,  0.90158 ,  2.512633],\n",
       "       [ 1.561583,  0.90158 ,  7.536496],\n",
       "       [ 1.561583,  0.90158 , 12.56036 ],\n",
       "       [ 0.      ,  3.606321,  2.512633],\n",
       "       [ 0.      ,  3.606321,  7.536496],\n",
       "       [ 0.      ,  3.606321, 12.56036 ],\n",
       "       [-1.561583,  6.311062,  2.512633],\n",
       "       [-1.561583,  6.311062,  7.536496],\n",
       "       [-1.561583,  6.311062, 12.56036 ],\n",
       "       [ 4.684749,  0.90158 ,  2.512633],\n",
       "       [ 4.684749,  0.90158 ,  7.536496],\n",
       "       [ 4.684749,  0.90158 , 12.56036 ],\n",
       "       [ 3.123166,  3.606321,  2.512633],\n",
       "       [ 3.123166,  3.606321,  7.536496],\n",
       "       [ 3.123166,  3.606321, 12.56036 ],\n",
       "       [ 1.561583,  6.311062,  2.512633],\n",
       "       [ 1.561583,  6.311062,  7.536496],\n",
       "       [ 1.561583,  6.311062, 12.56036 ],\n",
       "       [ 7.807914,  0.90158 ,  2.512633],\n",
       "       [ 7.807914,  0.90158 ,  7.536496],\n",
       "       [ 7.807914,  0.90158 , 12.56036 ],\n",
       "       [ 6.246332,  3.606321,  2.512633],\n",
       "       [ 6.246332,  3.606321,  7.536496],\n",
       "       [ 6.246332,  3.606321, 12.56036 ],\n",
       "       [ 4.684749,  6.311062,  2.512633],\n",
       "       [ 4.684749,  6.311062,  7.536496],\n",
       "       [ 4.684749,  6.311062, 12.56036 ],\n",
       "       [ 0.      ,  1.803161,  5.024565],\n",
       "       [ 0.      ,  1.803161, 10.048428],\n",
       "       [ 0.      ,  1.803161, 15.072292],\n",
       "       [-1.561583,  4.507901,  5.024565],\n",
       "       [-1.561583,  4.507901, 10.048428],\n",
       "       [-1.561583,  4.507901, 15.072292],\n",
       "       [-3.123166,  7.212642,  5.024565],\n",
       "       [-3.123166,  7.212642, 10.048428],\n",
       "       [-3.123166,  7.212642, 15.072292],\n",
       "       [ 3.123166,  1.803161,  5.024565],\n",
       "       [ 3.123166,  1.803161, 10.048428],\n",
       "       [ 3.123166,  1.803161, 15.072292],\n",
       "       [ 1.561583,  4.507901,  5.024565],\n",
       "       [ 1.561583,  4.507901, 10.048428],\n",
       "       [ 1.561583,  4.507901, 15.072292],\n",
       "       [ 0.      ,  7.212642,  5.024565],\n",
       "       [ 0.      ,  7.212642, 10.048428],\n",
       "       [ 0.      ,  7.212642, 15.072292],\n",
       "       [ 6.246332,  1.803161,  5.024565],\n",
       "       [ 6.246332,  1.803161, 10.048428],\n",
       "       [ 6.246332,  1.803161, 15.072292],\n",
       "       [ 4.684749,  4.507901,  5.024565],\n",
       "       [ 4.684749,  4.507901, 10.048428],\n",
       "       [ 4.684749,  4.507901, 15.072292],\n",
       "       [ 3.123166,  7.212642,  5.024565],\n",
       "       [ 3.123166,  7.212642, 10.048428],\n",
       "       [ 3.123166,  7.212642, 15.072292],\n",
       "       [ 1.561583,  0.90158 ,  4.420299],\n",
       "       [ 1.561583,  0.90158 ,  9.444162],\n",
       "       [ 1.561583,  0.90158 , 14.468026],\n",
       "       [ 0.      ,  3.606321,  4.420299],\n",
       "       [ 0.      ,  3.606321,  9.444162],\n",
       "       [ 0.      ,  3.606321, 14.468026],\n",
       "       [-1.561583,  6.311062,  4.420299],\n",
       "       [-1.561583,  6.311062,  9.444162],\n",
       "       [-1.561583,  6.311062, 14.468026],\n",
       "       [ 4.684749,  0.90158 ,  4.420299],\n",
       "       [ 4.684749,  0.90158 ,  9.444162],\n",
       "       [ 4.684749,  0.90158 , 14.468026],\n",
       "       [ 3.123166,  3.606321,  4.420299],\n",
       "       [ 3.123166,  3.606321,  9.444162],\n",
       "       [ 3.123166,  3.606321, 14.468026],\n",
       "       [ 1.561583,  6.311062,  4.420299],\n",
       "       [ 1.561583,  6.311062,  9.444162],\n",
       "       [ 1.561583,  6.311062, 14.468026],\n",
       "       [ 7.807914,  0.90158 ,  4.420299],\n",
       "       [ 7.807914,  0.90158 ,  9.444162],\n",
       "       [ 7.807914,  0.90158 , 14.468026],\n",
       "       [ 6.246332,  3.606321,  4.420299],\n",
       "       [ 6.246332,  3.606321,  9.444162],\n",
       "       [ 6.246332,  3.606321, 14.468026],\n",
       "       [ 4.684749,  6.311062,  4.420299],\n",
       "       [ 4.684749,  6.311062,  9.444162],\n",
       "       [ 4.684749,  6.311062, 14.468026],\n",
       "       [ 0.      ,  1.803161,  1.908367],\n",
       "       [ 0.      ,  1.803161,  6.932231],\n",
       "       [ 0.      ,  1.803161, 11.956094],\n",
       "       [-1.561583,  4.507901,  1.908367],\n",
       "       [-1.561583,  4.507901,  6.932231],\n",
       "       [-1.561583,  4.507901, 11.956094],\n",
       "       [-3.123166,  7.212642,  1.908367],\n",
       "       [-3.123166,  7.212642,  6.932231],\n",
       "       [-3.123166,  7.212642, 11.956094],\n",
       "       [ 3.123166,  1.803161,  1.908367],\n",
       "       [ 3.123166,  1.803161,  6.932231],\n",
       "       [ 3.123166,  1.803161, 11.956094],\n",
       "       [ 1.561583,  4.507901,  1.908367],\n",
       "       [ 1.561583,  4.507901,  6.932231],\n",
       "       [ 1.561583,  4.507901, 11.956094],\n",
       "       [ 0.      ,  7.212642,  1.908367],\n",
       "       [ 0.      ,  7.212642,  6.932231],\n",
       "       [ 0.      ,  7.212642, 11.956094],\n",
       "       [ 6.246332,  1.803161,  1.908367],\n",
       "       [ 6.246332,  1.803161,  6.932231],\n",
       "       [ 6.246332,  1.803161, 11.956094],\n",
       "       [ 4.684749,  4.507901,  1.908367],\n",
       "       [ 4.684749,  4.507901,  6.932231],\n",
       "       [ 4.684749,  4.507901, 11.956094],\n",
       "       [ 3.123166,  7.212642,  1.908367],\n",
       "       [ 3.123166,  7.212642,  6.932231],\n",
       "       [ 3.123166,  7.212642, 11.956094]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(sAlN_super3_mace_opt.struct.positions[0:],6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgo = Structure.from_file('data/test/MgO_mp-1265_computed.cif')\n",
    "from pymatgen.io.xyz import XYZ\n",
    "XYZ(mgo).write_file('data/test/mgo.xyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.60655347, 0.        , 1.50489435],\n",
       "       [0.86885116, 2.45748218, 1.50489435],\n",
       "       [0.        , 0.        , 3.0097887 ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgo.lattice.matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mace-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
